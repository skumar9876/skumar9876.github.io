<!DOCTYPE html>
<html lang="en">

  <head>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="My protfolio">
    <meta name="author" content="Saurabh Kumar">

    <title>Saurabh Kumar</title>

    <!-- Bootstrap core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom styles for this template -->
    <link href="css/3-col-portfolio.css" rel="stylesheet">

  </head>

  <body>

    <!-- Navigation -->
    <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
      <div class="container">
        <a class="navbar-brand" href="#">Saurabh Kumar</a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
          <span class="navbar-toggler-icon"></span>
        </button        <div class="collapse navbar-collapse" id="navbarResponsive">
          <ul class="navbar-nav ml-auto">
            <li class="nav-item">
              <a class="nav-link" href="index.html">Home
              </a>
            </li>
            <li class="nav-item active">
              <a class="nav-link" href="#">Research
                 <span class="sr-only">(current)</span>
              </a>
            </li>
          </ul>
        </div>
      </div>
    </nav>

    <!-- Page Content -->
    <div class="container">

      <!-- Page Heading -->
      <h1 class="my-4">Research Projects
        <small></small>
      </h1>

      <p>
        I conduct machine learning research, specifically in the areas of <b>computer vision</b> and <b>reinforcement learning (RL)</b>. Within RL, my recent work has focused on <b>interactive RL</b>, <b>hierarchical RL</b>, and <b>multi-agent RL</b>. Below are several of the projects that I worked on over the past couple years. Click on the project title to see documentation for the research completed.
      </p>

      <div class="row">
        <div class="col-lg-4 col-sm-6 portfolio-item">
          <div class="card h-100">
            <a href="documents/disease.pdf"><img class="card-img-top" src="images/disease.png" alt="" height="250" width="700"></a>
            <div class="card-body">
              <h4 class="card-title">
                <a href="documents/disease.pdf">Measurement of Alzheimerâ€™s Disease Diagnostic Accuracy</a>
              </h4>
              <p class="card-text">Completed during my senior year of high school at the Illinois Institute of Technology. I applied unsupervised and supervised learning algorithms to diagnoze Alzheimer's disease from MRI and PET brain scans.</p>
            </div>
          </div>
        </div>
        <div class="col-lg-4 col-sm-6 portfolio-item">
          <div class="card h-100">
            <a href="documents/singleshotlogo.pdf"><img class="card-img-top" src="images/singleshotlogo.png" alt=""></a>
            <div class="card-body">
              <h4 class="card-title">
                <a href="documents/singleshotlogo.pdf">Single Shot Logo: Brand Recognition and Detection in Near Realtime</a>
              </h4>
              <p class="card-text">Completed in Summer 2016 during my internship in Yahoo's Machine Learning and Vision team. I improved upon the <a href="https://arxiv.org/pdf/1512.02325.pdf"> Single Shot Multibox Detector Framework </a> to detect logos in images.</p>
            </div>
          </div>
        </div>
        <div class="col-lg-4 col-sm-6 portfolio-item">
          <div class="card h-100">
            <a href="documents/deeplearningforlogomining.pdf"><img class="card-img-top" src="images/dlforlogomining.png" alt="" height="250" width="700"></a>
            <div class="card-body">
              <h4 class="card-title">
                <a href="documents/deeplearningforlogomining.pdf">Deep Learning for Logo Mining</a>
              </h4>
              <p class="card-text">Completed in Summer 2016 during my internship in Yahoo's Machine Learning and Vision team. I used Exemplar SVMs with ConvNet features to mine logos in images.</p>
            </div>
          </div>
        </div>

        <div class="row">
        <div class="col-lg-4 col-sm-6 portfolio-item">
          <div class="card h-100">
            <a href="documents/policyshaping.pdf"><img class="card-img-top" src="images/policyshaping.png" alt=""></a>
            <div class="card-body">
              <h4 class="card-title">
                <a href="documents/policyshaping.pdf">Policy Shaping with Human Feedback</a>
              </h4>
              <p class="card-text">Completed in Spring and Fall 2016 at Georgia Tech. I developed infrastructure that allows a human to interact with an RL agent and provide feedback by speech as it learns to navigate a maze environment. I designed experiments to test how well the <a href="https://papers.nips.cc/paper/5187-policy-shaping-integrating-human-feedback-with-reinforcement-learning.pdf">policy shaping algorithm</a> works in practice. Based on this work, I received the <a href="https://goldwater.scholarsapply.org/"> Barry M. Goldwater Award. </a></p>
            </div>
          </div>
        </div>
        <div class="col-lg-4 col-sm-6 portfolio-item">
          <div class="card h-100">
            <a href="https://arxiv.org/abs/1705.08997"><img class="card-img-top" src="images/StateSpaceDecomposition.png" alt="" height="250" width="700"></a>
            <div class="card-body">
              <h4 class="card-title">
                <a href="https://arxiv.org/abs/1705.08997">State Space Decomposition and Subgoal Creation for Transfer in Deep Reinforcement Learning</a>
              </h4>
              <p class="card-text">Completed in Spring 2017 at Georgia Tech. We aimed to transfer an RL agent's skills on a simple task to a more complex task using a recurrent attention mechanism. This work was accepted to the <a href="http://rldm.org/rldm2017/"> 2017 Multi-disciplinary Conference in Reinforcement Learning and Decision Making. </a> </p>
            </div>
          </div>
        </div>
        <div class="col-lg-4 col-sm-6 portfolio-item">
          <div class="card h-100">
            <a><img class="card-img-top" src="images/FRL.png" alt=""></a>
            <div class="card-body">
              <h4 class="card-title">
                <a>Federated Control with Hierarchical Multi-Agent Deep Reinforcement Learning</a>
              </h4>
              <p class="card-text">Completed in Summer 2017 during my internship at Google Research and Machine Intelligence. We developed an approach to combine multi-agent RL and hierarchical RL to solve coordination problems among a multitude of agents. This work was accepted to the
              <a href="https://sites.google.com/view/hrlnips2017"> Hierarchical Reinforcement Learning Workshop </a> at NIPS 2017 (<a href="documents/fcrl_poster.pdf">poster</a> + contributed talk).</p>
            </div>
          </div>
        </div>
        <div class="col-lg-4 col-sm-6 portfolio-item">
          <div class="card h-100">
            <a><img class="card-img-top" src="images/compose.png" alt="" height="300" width="700"></a>
            <div class="card-body">
              <h4 class="card-title">
                <a href="https://arxiv.org/abs/1711.11289">Learning to Compose Skills</a>
              </h4>
              <p class="card-text">Completed in Fall 2017. We designed a differentiable framework to compose skills learned by separate RL agents. We focus on compositions that can be represented by <a href="https://arxiv.org/pdf/1704.04341.pdf"> Linear Temporal Logic</a> operators. This work was accepted to the <a href="https://sites.google.com/view/deeprl-symposium-nips2017/"> Deep Reinforcement Learning Symposium</a> at NIPS 2017 (<a href="documents/composenet_poster.pdf"> poster </a>).</p>
            </div>
          </div>
        </div>
        <div class="col-lg-4 col-sm-6 portfolio-item">
          <div class="card h-100">
            <a><img class="card-img-top" src="images/clusters.png" alt=""></a>
            <div class="card-body">
              <h4 class="card-title">
                <a>Unsupervised State Space Decomposition for Hierarchical Reinforcement Learning</a>
              </h4>
              <p class="card-text">Hierarchical RL splits an RL agent into a meta-controller, which selects subgoals, and a controller, which learns to complete subgoals. We use unsupervised clustering methods to decompose the state space of the meta-controller so that it can be trained using tabular Q-learning methods, significantly speeding up training. This work is ongoing at Georgia Tech.</p>
            </div>
          </div>
        </div>
      </div>
      <!-- /.row -->

    </div>
    <!-- /.container -->

    <!-- Footer -->
    <footer class="py-5 bg-dark">
      <div class="container">
        <p class="m-0 text-center text-white">Copyright &copy; Saurabh Kumar 2017</p>
      </div>
      <!-- /.container -->
    </footer>

    <!-- Bootstrap core JavaScript -->
    <script src="vendor/jquery/jquery.min.js"></script>
    <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

  </body>

</html>
